{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Coder_Hussam Qassim\n",
    "from random import random\n",
    "from numpy import array\n",
    "from numpy import cumsum\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "# create a sequence classification instance\n",
    "def get_sequence(n_timesteps):\n",
    "\t# create a sequence of random numbers in [0,1]\n",
    "\tX = array([random() for _ in range(n_timesteps)])\n",
    "\t# calculate cut-off value to change class values\n",
    "\tlimit = n_timesteps/4.0\n",
    "\t# determine the class outcome for each item in cumulative sequence\n",
    "\ty = array([0 if x < limit else 1 for x in cumsum(X)])\n",
    "\t# reshape input and output data to be suitable for LSTMs\n",
    "\tX = X.reshape(1, n_timesteps, 1)\n",
    "\ty = y.reshape(1, n_timesteps, 1)\n",
    "\treturn X, y\n",
    "\n",
    "def get_lstm_model(n_timesteps, backwards):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(20, input_shape=(n_timesteps, 1), return_sequences=True, go_backwards=backwards))\n",
    "\tmodel.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "def get_bi_lstm_model(n_timesteps, mode):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Bidirectional(LSTM(20, return_sequences=True), input_shape=(n_timesteps, 1), merge_mode=mode))\n",
    "\tmodel.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "def train_model(model, n_timesteps):\n",
    "\tloss = list()\n",
    "\tfor _ in range(250):\n",
    "\t\t# generate new random sequence\n",
    "\t\tX,y = get_sequence(n_timesteps)\n",
    "\t\t# fit model for one epoch on this sequence\n",
    "\t\thist = model.fit(X, y, epochs=1, batch_size=1, verbose=0)\n",
    "\t\tloss.append(hist.history['loss'][0])\n",
    "\treturn loss\n",
    "\n",
    "\n",
    "n_timesteps = 10\n",
    "results = DataFrame()\n",
    "# sum merge\n",
    "model = get_bi_lstm_model(n_timesteps, 'sum')\n",
    "results['bilstm_sum'] = train_model(model, n_timesteps)\n",
    "# mul merge\n",
    "model = get_bi_lstm_model(n_timesteps, 'mul')\n",
    "results['bilstm_mul'] = train_model(model, n_timesteps)\n",
    "# avg merge\n",
    "model = get_bi_lstm_model(n_timesteps, 'ave')\n",
    "results['bilstm_ave'] = train_model(model, n_timesteps)\n",
    "# concat merge\n",
    "model = get_bi_lstm_model(n_timesteps, 'concat')\n",
    "results['bilstm_con'] = train_model(model, n_timesteps)\n",
    "# line plot of results\n",
    "results.plot()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
